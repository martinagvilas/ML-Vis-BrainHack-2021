{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Preventing overfitting\n",
    "\n",
    "{TO-DO: Overview of notebook}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting/Underfitting and Bias/Variance\n",
    "\n",
    "- !! Explain what is overfitting and underfitting\n",
    "    - Show images\n",
    "- !! Explain Bias and Variance trade-off\n",
    "    - Show images\n",
    "    \n",
    "- We need to test the generalizability of our model, and evaluate its performance with data that has never seen (but comes from the same distribution as the training data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can illustrate the problem of overfitting using scikit-learn. Let's create a fake dataset for classification, and fit and score a support vector classifier that uses a polinomial kernel of degree 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC mean performance: 0.82\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create fake dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=100, n_features=20, n_informative=5, n_redundant=15, random_state=1\n",
    ")\n",
    "\n",
    "# Create and fit SVC\n",
    "svc = SVC(kernel='poly', degree=4, random_state=0).fit(X, y)\n",
    "\n",
    "# Score model\n",
    "print(f\"SVC mean performance: {svc.score(X, y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that here and during all the previous examples of this tutorial we have been using the dataset used for training (`X`) to also evaluate the performance of the model. As explained before, this could lead in overestimation of the model perfomance.\n",
    "\n",
    "Let's instead split our dataset into a training and testing set. We can do so using the method `train_test_split` in scikit-learn (read documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set: (75, 20)\n",
      "Shape of training labels: (75,)\n",
      "Shape of testing sett: (25, 20)\n",
      "Shape of testing labels: (25,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "print(f\"Shape of training set: {X_train.shape}\")\n",
    "print(f\"Shape of training labels: {y_train.shape}\")\n",
    "print(f\"Shape of testing sett: {X_test.shape}\")\n",
    "print(f\"Shape of testing labels: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, scikit-learn splits `X` into a training size of 75% and a testing size of 25%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we fit our estimator to the training set, and evaluate it both using the training and testing set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC mean accuracy on training data: 0.8\n",
      "SVC mean accuracy on testing data: 0.52\n"
     ]
    }
   ],
   "source": [
    "# Fit model to training set\n",
    "svc = SVC(kernel='poly', degree=5, random_state=0).fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model with training and testing data\n",
    "print(f\"SVC mean accuracy on training data: {svc.score(X_train, y_train)}\")\n",
    "print(f\"SVC mean accuracy on testing data: {svc.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the performance of the model drops significantly when evaluated on the testing set, indicating that our model may have overfitted to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Suppose we want our testing size to comprise 20% of the original dataset. Modify `train_test_split` to achieve this aim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Fortunately, there exists various methods that help reducing overfitting during training. In this notebook, we will revise two of them: _cross-validation_ and _regularization_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation\n",
    "\n",
    "- !! Why use cross-validation\n",
    "    - reduce overfitting\n",
    "    - test generalization\n",
    "- !! Types of cross-validation\n",
    "- !! Show images of cross-validation\n",
    "- !! Give as examples how to implement Stratified K Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=500, n_features=300, n_informative=100, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a stratified cross-validation object using `StratifiedKFold` (read documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold)). We will use 3 splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a logistic regression model and evaluate the model using the cross-validation object defined above and the `cross_validate` method (read documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    clf, X, y, scoring='accuracy', cv=skf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the output of the cross-validation procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.01362705, 0.00827885, 0.00480318]),\n",
       " 'score_time': array([0.00795507, 0.00030303, 0.00038409]),\n",
       " 'test_score': array([0.91176471, 0.90909091, 0.81818182])}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also return the training scores and estimators used in each split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(\n",
    "    clf, X, y, scoring='accuracy', cv=skf,\n",
    "    return_train_score=True,\n",
    "    return_estimator=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00624418, 0.00407386, 0.00546193]),\n",
       " 'score_time': array([0.00039387, 0.00029588, 0.00043488]),\n",
       " 'estimator': [LogisticRegression(max_iter=1000),\n",
       "  LogisticRegression(max_iter=1000),\n",
       "  LogisticRegression(max_iter=1000)],\n",
       " 'test_score': array([0.91176471, 0.90909091, 0.81818182]),\n",
       " 'train_score': array([0.89393939, 0.91044776, 0.94029851])}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way we can access the estimator fitted in a specific split of the data, and use it to predict data, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = 0\n",
    "estimator_split = cv_results[\"estimator\"][0]\n",
    "estimator_split.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{TO-DO: show how in the training and testing set we perform the preprocessing steps outside the testing too}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Can you read the documentation of `RepeatedStratifiedKFold` [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedStratifiedKFold.html#sklearn.model_selection.RepeatedStratifiedKFold), understand it and implement it as above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "\n",
    "- !! Another way of preventing overfitting is to regularize our models\n",
    "- !! Explain what is regularization\n",
    "    - Regularization penalizes your model during training to avoid overfitting. More specifically, it adds a penalty to the _loss_ function of your model.\n",
    "- There are two main types of regularization:\n",
    "    - L1 or _Lasso_: Makes the coefficients sparse, meaning some of them are shrinked to 0.\n",
    "        - {add formula}\n",
    "        - {the function looks more simple}\n",
    "    - L2 or _Ridge_: Makes the coefficients smaller.\n",
    "        - {add formula}\n",
    "        - {the function looks smoother}\n",
    "- Explain lambda, alpha (hyperparameter)\n",
    "- !! Explain the difference between L1 and L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{TO-DO}: Improve the whole regularization section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some regularization to our previous model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a logistic regression model in scikit-learn and inspect its parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': 'l2',\n",
       " 'dual': False,\n",
       " 'tol': 0.0001,\n",
       " 'C': 1.0,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'class_weight': None,\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'verbose': 0,\n",
       " 'warm_start': False,\n",
       " 'n_jobs': None,\n",
       " 'l1_ratio': None}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "vars(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, by default scikit-learn penalizes logistic regression models using _Ridge (L2)_ regularization. If you read the documentation of `LogisticRegression` [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) you will also notice that the parameter `C` determines the strenght of the regularization applied. By default this value is set to 1. Lower values will indicate stronger regularization.\n",
    "\n",
    "{TO-DO}: explain this in more detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n",
      "0.84\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty=\"l2\", C=0.01).fit(X_train, y_train)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92\n",
      "0.92\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty=\"l2\", C=100).fit(X_train, y_train)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to implement this in a linear regression model?\n",
    "\n",
    "{TO-DO: expand this}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6884727381337423\n",
      "0.1874785187965038\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge().fit(X_train, y_train)\n",
    "print(ridge.score(X_train, y_train))\n",
    "print(ridge.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(TODO: Explain better this part)\n",
    "\n",
    "The value of regularization that gives the best performance in not known beforehand. Some people search the best performance value manually using the whole training and testing dataset. This could lead to overestimating the real performance of the model. Instead, good practice would be to tune this parameter the same as the weights of the model. This leads us to understanding the concept of __hyper-parameter tuning__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter tuning\n",
    "\n",
    "- What are hyperparameters\n",
    "- Why we should tune our hyperparametes using cross validation and not search them manually.\n",
    "- Concept of Nested Cross Validation\n",
    "- What is, and how to perform, `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(noise=0.352, random_state=1, n_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=10, n_splits=10, random_state=0),\n",
       "             estimator=SVC(random_state=0),\n",
       "             param_grid=[{'kernel': ['linear']},\n",
       "                         {'degree': [2, 3], 'kernel': ['poly']},\n",
       "                         {'kernel': ['rbf']}],\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid = [\n",
    "    {'kernel': ['linear']},\n",
    "    {'kernel': ['poly'], 'degree': [2, 3]},\n",
    "    {'kernel': ['rbf']}\n",
    "]\n",
    "\n",
    "svc = SVC(random_state=0)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(\n",
    "    n_splits=10, n_repeats=10, random_state=0\n",
    ")\n",
    "\n",
    "search = GridSearchCV(\n",
    "    estimator=svc, param_grid=param_grid,\n",
    "    scoring='roc_auc', cv=cv\n",
    ")\n",
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_degree</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split93_test_score</th>\n",
       "      <th>split94_test_score</th>\n",
       "      <th>split95_test_score</th>\n",
       "      <th>split96_test_score</th>\n",
       "      <th>split97_test_score</th>\n",
       "      <th>split98_test_score</th>\n",
       "      <th>split99_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'kernel': 'linear'}</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.077846</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>poly</td>\n",
       "      <td>2</td>\n",
       "      <td>{'degree': 2, 'kernel': 'poly'}</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.6852</td>\n",
       "      <td>0.169106</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>poly</td>\n",
       "      <td>3</td>\n",
       "      <td>{'degree': 3, 'kernel': 'poly'}</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.9044</td>\n",
       "      <td>0.098776</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'kernel': 'rbf'}</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.079297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_kernel  \\\n",
       "0       0.000899      0.000336         0.001060        0.000373       linear   \n",
       "1       0.000904      0.000205         0.000979        0.000233         poly   \n",
       "2       0.000840      0.000173         0.000959        0.000214         poly   \n",
       "3       0.000996      0.000280         0.001243        0.000448          rbf   \n",
       "\n",
       "  param_degree                           params  split0_test_score  \\\n",
       "0          NaN             {'kernel': 'linear'}               0.96   \n",
       "1            2  {'degree': 2, 'kernel': 'poly'}               0.76   \n",
       "2            3  {'degree': 3, 'kernel': 'poly'}               1.00   \n",
       "3          NaN                {'kernel': 'rbf'}               0.92   \n",
       "\n",
       "   split1_test_score  split2_test_score  ...  split93_test_score  \\\n",
       "0               0.84               0.76  ...                0.76   \n",
       "1               0.64               0.56  ...                0.52   \n",
       "2               0.72               0.76  ...                0.68   \n",
       "3               0.72               0.76  ...                0.72   \n",
       "\n",
       "   split94_test_score  split95_test_score  split96_test_score  \\\n",
       "0                0.92                1.00                0.92   \n",
       "1                0.48                0.68                0.68   \n",
       "2                0.96                1.00                0.96   \n",
       "3                0.92                1.00                0.96   \n",
       "\n",
       "   split97_test_score  split98_test_score  split99_test_score  \\\n",
       "0                0.92                1.00                0.84   \n",
       "1                0.76                0.84                0.52   \n",
       "2                0.92                1.00                0.56   \n",
       "3                1.00                1.00                0.84   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.9300        0.077846                2  \n",
       "1           0.6852        0.169106                4  \n",
       "2           0.9044        0.098776                3  \n",
       "3           0.9400        0.079297                1  \n",
       "\n",
       "[4 rows x 110 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(search.cv_results_)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kernel</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rbf</th>\n",
       "      <td>{'kernel': 'rbf'}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.079297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>{'kernel': 'linear'}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.077846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_poly</th>\n",
       "      <td>{'degree': 3, 'kernel': 'poly'}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9044</td>\n",
       "      <td>0.098776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_poly</th>\n",
       "      <td>{'degree': 2, 'kernel': 'poly'}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6852</td>\n",
       "      <td>0.169106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 params  rank_test_score  mean_test_score  \\\n",
       "kernel                                                                      \n",
       "rbf                   {'kernel': 'rbf'}                1           0.9400   \n",
       "linear             {'kernel': 'linear'}                2           0.9300   \n",
       "3_poly  {'degree': 3, 'kernel': 'poly'}                3           0.9044   \n",
       "2_poly  {'degree': 2, 'kernel': 'poly'}                4           0.6852   \n",
       "\n",
       "        std_test_score  \n",
       "kernel                  \n",
       "rbf           0.079297  \n",
       "linear        0.077846  \n",
       "3_poly        0.098776  \n",
       "2_poly        0.169106  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = results_df.sort_values(by=['rank_test_score'])\n",
    "results_df = (\n",
    "    results_df\n",
    "    .set_index(results_df[\"params\"].apply(\n",
    "        lambda x: \"_\".join(str(val) for val in x.values()))\n",
    "    )\n",
    "    .rename_axis('kernel')\n",
    ")\n",
    "results_df[\n",
    "    ['params', 'rank_test_score', 'mean_test_score', 'std_test_score']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn how to perform statistical evaluation over these examples [here](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_stats.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Can you use `GridSearchCV` to search for the best value of `C` for a logistic regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check your knowledge\n",
    "\n",
    "{TO-DO}\n",
    "\n",
    "Load the dataset pre-processed in notebook 1 {give name}, and:\n",
    "\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "\n",
    "Answer the following questions:\n",
    "\n",
    "1. \n",
    "2.\n",
    "3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional resources\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
